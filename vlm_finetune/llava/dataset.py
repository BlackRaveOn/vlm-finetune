"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ LLaVA (Large Language and Vision Assistant)
–¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

–û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã) –≤ —Ñ–æ—Ä–º–∞—Ç,
—É–¥–æ–±–Ω—ã–π –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å `LlavaModel` –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`.  
–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –¥–∏–∞–ª–æ–≥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –≥–¥–µ
–≤—Ö–æ–¥ –≤–∫–ª—é—á–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –∞ –≤—ã—Ö–æ–¥ ‚Äî —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏.

–ö–ª–∞—Å—Å—ã:
    LLavaDataset: –ö–ª–∞—Å—Å PyTorch Dataset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö LLaVA.
"""

import json
import torch
from PIL import Image
from torch.utils.data import Dataset
from transformers.models.llava.processing_llava import LlavaProcessor


class LLavaDataset(Dataset):
    """
    –ö–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–µ–ª–∏ LLaVA.

    –î–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON, —Å–æ–¥–µ—Ä–∂–∞—â–µ–≥–æ –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º, —Ç–µ–∫—Å—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤,
    –∏ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ `LlavaProcessor` –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Ö –≤ —Ç–µ–Ω–∑–æ—Ä—ã, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å –º–æ–¥–µ–ª—å—é LLaVA.

    –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤—Ö–æ–¥–Ω–æ–≥–æ JSON:
    [
        {
            "image_path": "path/to/image1.jpg",
            "prompt": "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —Ñ–æ—Ç–æ?",
            "answer": "–ù–∞ —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ —Å–æ–±–∞–∫–∞."
        },
        ...
    ]

    –ê—Ç—Ä–∏–±—É—Ç—ã:
        data (list[dict[str, str]]): –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑ JSON –¥–∞–Ω–Ω—ã–µ.
        processor (LlavaProcessor): –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
        prompt (str | None): –û–±—â–∏–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –∑–∞–¥–∞–Ω –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.
    """

    def __init__(self, dataset_path: str, processor: LlavaProcessor, prompt: str | None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            dataset_path: str
                –ü—É—Ç—å –∫ JSON-—Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞.
            processor: LlavaProcessor
                –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞
                –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
            prompt: str | None
                –ë–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω, –µ—Å–ª–∏ –≤ –ø—Ä–∏–º–µ—Ä–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–≤–æ–π.
        
        –ò—Å–∫–ª—é—á–µ–Ω–∏—è:
            FileNotFoundError:
                –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–π JSON-—Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
            json.JSONDecodeError:
                –ï—Å–ª–∏ JSON-—Ñ–∞–π–ª –∏–º–µ–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
        """
        with open(dataset_path, encoding="utf-8") as f:
            self.data: list[dict[str, str]] = json.load(f)
        self.processor = processor
        self.prompt = prompt

    def __len__(self) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (—Å—Ç—Ä–æ–∫) –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.
        """
        return len(self.data)

    def __getitem__(self, idx: int) -> dict[str, torch.Tensor]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π –≤ —Ñ–æ—Ä–º–∞—Ç, –ø—Ä–∏–≥–æ–¥–Ω—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            idx: int
                –ò–Ω–¥–µ–∫—Å –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            dict[str, torch.Tensor]:
                –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏:
                    - "input_ids": —Ç–µ–Ω–∑–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞;
                    - "attention_mask": –º–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è;
                    - "pixel_values": –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è;
                    - "labels": —Ü–µ–ª–µ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–≤—Å—ë –¥–æ "ASSISTANT:" –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–æ -100).

        –ò—Å–∫–ª—é—á–µ–Ω–∏—è:
            KeyError:
                –ï—Å–ª–∏ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á `image_path`.
            FileNotFoundError:
                –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
            ValueError:
                –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–µ —Å–º–æ–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
        """
        item = self.data[idx]
        image_path = item["image_path"]
        answer = item["answer"]
        prompt = item.get("prompt", self.prompt)

        image = Image.open(image_path).convert("RGB")

        conversation = [
            {
                "role": "user",
                "content": [
                    {"type": "image"},
                    {"type": "text", "text": prompt},
                ],
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": answer + self.processor.tokenizer.eos_token},
                ],
            },
        ]

        text = self.processor.apply_chat_template(
            conversation,
            tokenize=False,
            add_generation_prompt=False,
        )

        encoding: dict[str, torch.Tensor] = self.processor(
            text=text,
            images=image,
            return_tensors="pt",
            padding=False
        )

        input_ids = encoding["input_ids"].squeeze(0)
        attention_mask = encoding["attention_mask"].squeeze(0)
        pixel_values = encoding["pixel_values"].squeeze(0)

        # üîç –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –Ω–∞—á–∞–ª–∞ "ASSISTANT:"
        tokenized_assistant: torch.Tensor = self.processor.tokenizer(
            "ASSISTANT:",
            add_special_tokens=False
        )["input_ids"]

        start_idx = None
        for i in range(len(input_ids) - len(tokenized_assistant)):
            if torch.equal(input_ids[i:i + len(tokenized_assistant)], torch.tensor(tokenized_assistant)):
                start_idx = i + len(tokenized_assistant)
                break

        if start_idx is None:
            start_idx = 0  # fallback

        labels = input_ids.clone()
        labels[:start_idx] = -100  # –º–∞—Å–∫–∏—Ä—É–µ–º –≤—Å—ë –¥–æ –Ω–∞—á–∞–ª–∞ –æ—Ç–≤–µ—Ç–∞

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "pixel_values": pixel_values,
            "labels": labels,
        }
